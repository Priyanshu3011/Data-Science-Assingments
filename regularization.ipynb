{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ce00ffd-f4cf-417e-8c38-a5ada90bcba8",
   "metadata": {},
   "source": [
    "## Topic : `Upderstandign Regularization`\n",
    "___"
   ]
  },
  {
   "attachments": {
    "746f3e08-e7bc-4c76-b5c7-f4d7f20115ad.png": {
     "image/png": "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"
    },
    "cb44a458-045c-4202-85b6-2c9362bf1732.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "5e59135f-536c-4910-a9c9-624e03eeef2c",
   "metadata": {},
   "source": [
    "### 1. `What is regularization in the context of deep learning? Why is it important?`\n",
    "\n",
    "Regularization is a technique used in deep learning to prevent overfitting and improve the generalization of a model. Overfitting occurs when a model becomes too complex and starts to memorize the training data rather than learning underlying patterns and relationships. As a result, the model performs well on the training data but fails to generalize to new, unseen data.\n",
    "\n",
    "Regularization is important because it helps to control the complexity of the model by adding a penalty term to the loss function. This penalty discourages the model from assigning excessive importance to certain features or parameters during the training process. By doing so, regularization encourages the model to focus on more robust and generalizable patterns, reducing the risk of overfitting and leading to better performance on unseen data.\n",
    "\n",
    "### 2. `Explain the bias-variance tradeoff and how regularization helps in addressing this tradeoff.`\n",
    "\n",
    "The bias-variance tradeoff is a fundamental concept in supervised learning, including deep learning. It describes the balance between two sources of error in a model: bias and variance.\n",
    "\n",
    "- `Bias`: Bias is the error introduced by making overly simplistic assumptions about the underlying data distribution. High bias models may not capture the complexity of the data and tend to underfit, leading to poor performance on both training and test data.\n",
    "\n",
    "- `Variance`: Variance is the error caused by the model's sensitivity to fluctuations in the training data. High variance models are highly flexible and can fit the training data well, but they are prone to overfitting, performing poorly on unseen data.\n",
    "\n",
    "Regularization helps address the bias-variance tradeoff by reducing variance without increasing bias significantly. When a model is regularized, it imposes constraints on the model's parameters, discouraging them from taking extreme or complex values. This constraint prevents the model from fitting the noise in the training data too closely, reducing variance and making the model more robust to new data. Consequently, regularization improves generalization by striking a balance between fitting the training data well and avoiding overfitting.\n",
    "\n",
    "### 3. `Describe the concept of L1 and L2 regularization. How do they differ in terms of penalty calculation and their effects on the model?`\n",
    "\n",
    "`L1 and L2 regularization are two commonly used techniques to add regularization to deep learning models:`\n",
    "\n",
    "- `L1 Regularization (Lasso Regularization):`\n",
    "L1 regularization adds a penalty to the loss function that is proportional to the absolute values of the model's parameters. The penalty term is the sum of the absolute values of the model's weights multiplied by a regularization hyperparameter (lambda or alpha). The L1 regularization term can be mathematically represented as: regularization_term = lambda * Î£|weight_i|\n",
    "\n",
    "![image.png](attachment:746f3e08-e7bc-4c76-b5c7-f4d7f20115ad.png)\n",
    "\n",
    "The effect of L1 regularization is to drive some of the model's weights to exactly zero. This leads to feature selection, as some features become irrelevant to the model, effectively reducing the model's complexity and making it more interpretable. L1 regularization creates a sparse model, which means it only retains the most important features, making it useful when dealing with high-dimensional data and feature selection.\n",
    "\n",
    "- `L2 Regularization (Ridge Regularization):`\n",
    "L2 regularization adds a penalty to the loss function that is proportional to the squared values of the model's parameters. The penalty term is the sum of the squares of the model's weights multiplied by a regularization hyperparameter (lambda or alpha). The L2 regularization term can be mathematically represented as: regularization_term = \n",
    "\n",
    "![image.png](attachment:cb44a458-045c-4202-85b6-2c9362bf1732.png)\n",
    "\n",
    "The effect of L2 regularization is to shrink the model's weights towards zero without driving them exactly to zero. This leads to a more distributed reduction of weight magnitudes, effectively controlling the overall complexity of the model. L2 regularization does not create a sparse model, and all features are retained. It is useful when all features are expected to contribute to the model's performance, and we want to prevent any one feature from dominating the predictions.\n",
    "\n",
    "### `4. Discuss the role of regularization in preventing overfitting and improving the generalization of deep learning models.`\n",
    "\n",
    "Regularization plays a crucial role in preventing overfitting and improving the generalization of deep learning models by controlling model complexity:\n",
    "\n",
    "1. `Reducing Overfitting`: Regularization helps prevent overfitting by penalizing complex models during training. As the model learns to minimize the loss function, it also has to consider the regularization term, which discourages the model from assigning excessively large weights to any particular feature or parameter. This discouragement prevents the model from fitting noise in the training data too closely and reduces the chances of overfitting.\n",
    "\n",
    "2.` Controlling Model Complexity`: Overfitting often occurs when a model becomes too complex, capturing noise and idiosyncrasies in the training data rather than general patterns. Regularization adds a penalty for complex models, guiding the learning process to favor simpler models that capture more generalizable patterns. By controlling the model's complexity, regularization helps strike a balance between underfitting and overfitting, leading to improved performance on unseen data.\n",
    "\n",
    "3. `Improving Generalization`: Regularization encourages the model to learn robust and generalizable patterns in the data. By preventing the model from focusing solely on the training data, it can better adapt to new and unseen data instances. This improves the model's ability to generalize well to data it has never encountered before, making it more reliable and useful in real-world applications.\n",
    "\n",
    "In conclusion, regularization is a critical tool in the deep learning toolbox that helps control model complexity, prevent overfitting, and improve the generalization of models. By adding regularization techniques like L1 or L2 regularization, deep learning practitioners can train more robust and reliable models that perform well on both training data and new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df06304d-17fc-4980-a0ba-3e3e7c4dc0bc",
   "metadata": {},
   "source": [
    "Explain in long term answers\n",
    "Part 2: Regularization Technique\n",
    "1. Explain Dropout regularization and how it works to reduce overfitting. Discuss the impact of Dropout on model training and inference.\n",
    "2. Describe the concept of Early stopping as a form of regularization. How does it help prevent overfitting during the training process.\n",
    "3. Explain the concept of Batch Normalization and its role as a form of regularization. How does Batch Normalization help in preventing overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f67332-6769-489f-b935-760f2b47d95e",
   "metadata": {},
   "source": [
    "##  topic 2:`Relarization technique`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbb6c5d-79a0-4f78-967c-364016b32a8a",
   "metadata": {},
   "source": [
    "### `1. Dropout Regularization:`\n",
    "Dropout is a powerful regularization technique used to prevent overfitting in neural networks. Overfitting occurs when a model becomes too specialized in learning the training data and fails to generalize well to new, unseen data. Dropout helps combat this issue by randomly dropping out (deactivating) some neurons during training.\n",
    "\n",
    "`How Dropout Works:`\n",
    "During the forward pass of the training process, dropout randomly deactivates a fraction of neurons in a layer with a specified dropout rate (typically between 0.2 to 0.5). This means that these deactivated neurons will not contribute to the computations of the next layer during that specific forward pass. Essentially, the dropout process creates a form of model ensemble, where different subsets of neurons are active for each training iteration. This can be seen as training multiple sub-networks simultaneously.\n",
    "\n",
    "`Impact on Model Training:`\n",
    "The main effect of dropout is that it introduces noise and redundancy in the network during training. This encourages the model to learn more robust and general features, as it cannot rely too heavily on any specific set of neurons. It also reduces co-adaptation among neurons, which can lead to a more diverse representation of the data and ultimately prevents overfitting.\n",
    "\n",
    "`Impact on Inference:`\n",
    "During inference (when the trained model is used to make predictions on new data), dropout is usually turned off, and all neurons are active. However, the weights of the neurons are typically scaled by the dropout rate during inference to ensure the expected output is consistent with the model's behavior during training.\n",
    "\n",
    "### `2. Early Stopping as Regularization:`\n",
    "Early stopping is a form of regularization that prevents overfitting by monitoring the model's performance on a validation dataset during the training process. The idea is to stop training the model before it starts to overfit the training data.\n",
    "\n",
    "`How Early Stopping Works:`\n",
    "When training a neural network, we usually split the data into three sets: training set, validation set, and test set. The training set is used to update the model's weights, the validation set is used to monitor the model's performance, and the test set is used to evaluate the final performance after training.\n",
    "\n",
    "During training, the model's performance on the validation set is periodically checked. If the validation performance starts to degrade or plateau, it suggests that the model is starting to overfit the training data and may not generalize well. At this point, early stopping is triggered, and training is halted.\n",
    "\n",
    "`Impact on Preventing Overfitting:`\n",
    "Early stopping prevents overfitting by stopping the training process at an optimal point when the model's performance on the validation set is best. It ensures that the model is not exposed to additional training epochs that may lead to overfitting. By finding the right balance between underfitting and overfitting, early stopping helps the model generalize better to new data.\n",
    "\n",
    "### `3. Batch Normalization as Regularization:`\n",
    "Batch Normalization is a technique used to stabilize and accelerate the training process of neural networks. While its primary goal is not directly regularization, it can have a regularization effect on the model.\n",
    "\n",
    "`How Batch Normalization Works:`\n",
    "In neural networks, during each training iteration, the inputs to each layer may have different distributions, which can slow down training. Batch Normalization addresses this issue by normalizing the inputs of each layer to have a mean of zero and a standard deviation of one. It does this by normalizing the activations using the mean and variance calculated over a batch of training samples. Additionally, it introduces learnable parameters (gamma and beta) that allow the model to adapt the scale and shift of the normalized values.\n",
    "\n",
    "`Impact on Preventing Overfitting:`\n",
    "Batch Normalization helps prevent overfitting by acting as a form of noise during training. The normalization process introduces some randomness into the activations of each layer because it depends on the statistics calculated over a batch of samples. This added noise can help regularize the model by reducing the dependence on specific instances in the training data and enhancing its ability to generalize to new data.\n",
    "\n",
    "Furthermore, Batch Normalization provides some regularization benefits by acting as a form of adaptive regularization. The learnable parameters gamma and beta allow the model to adjust the normalization statistics during training, which can help control the overall capacity of the network and prevent it from overfitting.\n",
    "\n",
    "In summary, Dropout, Early Stopping, and Batch Normalization are all effective regularization techniques that help combat overfitting in neural networks. They encourage the model to learn more general and robust representations of the data, prevent over-reliance on specific patterns, and ultimately improve the model's ability to generalize to new, unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6d2467-7ff5-430f-af21-2e3dee9ec8b9",
   "metadata": {},
   "source": [
    "## Topic 3: `Applying Regularization.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c37718c4-902c-47c2-918d-158372c60d5e",
   "metadata": {},
   "source": [
    "### 1 `Implement Dropout Regularization`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d900ede6-18f3-44d9-bd06-858b1a5c7e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-21 05:20:16.525679: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-21 05:20:16.598281: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-07-21 05:20:16.599484: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-21 05:20:17.873708: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11490434/11490434 [==============================] - 2s 0us/step\n",
      "Epoch 1/20\n",
      "422/422 [==============================] - 5s 9ms/step - loss: 0.4049 - accuracy: 0.8744 - val_loss: 0.1397 - val_accuracy: 0.9567\n",
      "Epoch 2/20\n",
      "422/422 [==============================] - 3s 8ms/step - loss: 0.1824 - accuracy: 0.9470 - val_loss: 0.1075 - val_accuracy: 0.9668\n",
      "Epoch 3/20\n",
      "422/422 [==============================] - 4s 9ms/step - loss: 0.1433 - accuracy: 0.9563 - val_loss: 0.0910 - val_accuracy: 0.9727\n",
      "Epoch 4/20\n",
      "422/422 [==============================] - 4s 8ms/step - loss: 0.1218 - accuracy: 0.9636 - val_loss: 0.0812 - val_accuracy: 0.9748\n",
      "Epoch 5/20\n",
      "422/422 [==============================] - 3s 8ms/step - loss: 0.1044 - accuracy: 0.9688 - val_loss: 0.0648 - val_accuracy: 0.9810\n",
      "Epoch 6/20\n",
      "422/422 [==============================] - 4s 8ms/step - loss: 0.0930 - accuracy: 0.9712 - val_loss: 0.0663 - val_accuracy: 0.9812\n",
      "Epoch 7/20\n",
      "422/422 [==============================] - 3s 8ms/step - loss: 0.0889 - accuracy: 0.9718 - val_loss: 0.0623 - val_accuracy: 0.9840\n",
      "Epoch 8/20\n",
      "422/422 [==============================] - 3s 8ms/step - loss: 0.0804 - accuracy: 0.9752 - val_loss: 0.0652 - val_accuracy: 0.9803\n",
      "Epoch 9/20\n",
      "422/422 [==============================] - 3s 8ms/step - loss: 0.0727 - accuracy: 0.9776 - val_loss: 0.0590 - val_accuracy: 0.9807\n",
      "Epoch 10/20\n",
      "422/422 [==============================] - 3s 8ms/step - loss: 0.0708 - accuracy: 0.9782 - val_loss: 0.0567 - val_accuracy: 0.9825\n",
      "Epoch 11/20\n",
      "422/422 [==============================] - 3s 8ms/step - loss: 0.0638 - accuracy: 0.9800 - val_loss: 0.0597 - val_accuracy: 0.9815\n",
      "Epoch 12/20\n",
      "422/422 [==============================] - 3s 8ms/step - loss: 0.0635 - accuracy: 0.9800 - val_loss: 0.0610 - val_accuracy: 0.9837\n",
      "Epoch 13/20\n",
      "422/422 [==============================] - 3s 8ms/step - loss: 0.0608 - accuracy: 0.9804 - val_loss: 0.0553 - val_accuracy: 0.9845\n",
      "Epoch 14/20\n",
      "422/422 [==============================] - 3s 8ms/step - loss: 0.0541 - accuracy: 0.9825 - val_loss: 0.0505 - val_accuracy: 0.9857\n",
      "Epoch 15/20\n",
      "422/422 [==============================] - 4s 8ms/step - loss: 0.0563 - accuracy: 0.9824 - val_loss: 0.0630 - val_accuracy: 0.9827\n",
      "Epoch 16/20\n",
      "422/422 [==============================] - 3s 8ms/step - loss: 0.0534 - accuracy: 0.9827 - val_loss: 0.0556 - val_accuracy: 0.9852\n",
      "Epoch 17/20\n",
      "422/422 [==============================] - 3s 8ms/step - loss: 0.0514 - accuracy: 0.9833 - val_loss: 0.0576 - val_accuracy: 0.9850\n",
      "Epoch 18/20\n",
      "422/422 [==============================] - 3s 8ms/step - loss: 0.0478 - accuracy: 0.9844 - val_loss: 0.0578 - val_accuracy: 0.9832\n",
      "Epoch 19/20\n",
      "422/422 [==============================] - 3s 8ms/step - loss: 0.0476 - accuracy: 0.9841 - val_loss: 0.0567 - val_accuracy: 0.9857\n",
      "Epoch 20/20\n",
      "422/422 [==============================] - 3s 8ms/step - loss: 0.0468 - accuracy: 0.9850 - val_loss: 0.0572 - val_accuracy: 0.9847\n",
      "Epoch 1/20\n",
      "422/422 [==============================] - 4s 7ms/step - loss: 0.2407 - accuracy: 0.9303 - val_loss: 0.1111 - val_accuracy: 0.9685\n",
      "Epoch 2/20\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0880 - accuracy: 0.9733 - val_loss: 0.0757 - val_accuracy: 0.9777\n",
      "Epoch 3/20\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0552 - accuracy: 0.9825 - val_loss: 0.0713 - val_accuracy: 0.9807\n",
      "Epoch 4/20\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0381 - accuracy: 0.9881 - val_loss: 0.0686 - val_accuracy: 0.9775\n",
      "Epoch 5/20\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0277 - accuracy: 0.9910 - val_loss: 0.0586 - val_accuracy: 0.9820\n",
      "Epoch 6/20\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0209 - accuracy: 0.9929 - val_loss: 0.0703 - val_accuracy: 0.9798\n",
      "Epoch 7/20\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0187 - accuracy: 0.9936 - val_loss: 0.0726 - val_accuracy: 0.9818\n",
      "Epoch 8/20\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0155 - accuracy: 0.9948 - val_loss: 0.0728 - val_accuracy: 0.9818\n",
      "Epoch 9/20\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0163 - accuracy: 0.9944 - val_loss: 0.0779 - val_accuracy: 0.9810\n",
      "Epoch 10/20\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0121 - accuracy: 0.9960 - val_loss: 0.0815 - val_accuracy: 0.9795\n",
      "Epoch 11/20\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0095 - accuracy: 0.9967 - val_loss: 0.0832 - val_accuracy: 0.9808\n",
      "Epoch 12/20\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.1007 - val_accuracy: 0.9798\n",
      "Epoch 13/20\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0098 - accuracy: 0.9970 - val_loss: 0.0736 - val_accuracy: 0.9843\n",
      "Epoch 14/20\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.0794 - val_accuracy: 0.9835\n",
      "Epoch 15/20\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0098 - accuracy: 0.9965 - val_loss: 0.0916 - val_accuracy: 0.9817\n",
      "Epoch 16/20\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0101 - accuracy: 0.9963 - val_loss: 0.0856 - val_accuracy: 0.9820\n",
      "Epoch 17/20\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0081 - accuracy: 0.9976 - val_loss: 0.0867 - val_accuracy: 0.9825\n",
      "Epoch 18/20\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0049 - accuracy: 0.9981 - val_loss: 0.0920 - val_accuracy: 0.9833\n",
      "Epoch 19/20\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0044 - accuracy: 0.9986 - val_loss: 0.1122 - val_accuracy: 0.9797\n",
      "Epoch 20/20\n",
      "422/422 [==============================] - 3s 7ms/step - loss: 0.0108 - accuracy: 0.9965 - val_loss: 0.0898 - val_accuracy: 0.9840\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Preprocess the data\n",
    "X_train = X_train.reshape(-1, 28*28) / 255.0\n",
    "X_test = X_test.reshape(-1, 28*28) / 255.0\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes=10)\n",
    "\n",
    "# Split the training data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "# Create the deep learning model with Dropout regularization\n",
    "model_with_dropout = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(28*28,)),\n",
    "    Dropout(0.5),  # Add Dropout layer with 50% dropout rate\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_with_dropout.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model with Dropout regularization\n",
    "history_with_dropout = model_with_dropout.fit(X_train, y_train, epochs=20, batch_size=128, validation_data=(X_val, y_val))\n",
    "\n",
    "# Create the deep learning model without Dropout regularization\n",
    "model_without_dropout = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(28*28,)),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model_without_dropout.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model without Dropout regularization\n",
    "history_without_dropout = model_without_dropout.fit(X_train, y_train, epochs=20, batch_size=128, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8638fdd7-a756-436e-9656-54d6f57156e3",
   "metadata": {},
   "source": [
    "### 2. `Considerations and Tradeoffs for Choosing Regularization Techniques:`\n",
    "When choosing the appropriate regularization technique for a deep learning task, several considerations and tradeoffs come into play:\n",
    "\n",
    "a. `Dataset Size`: The size of the dataset plays a significant role in choosing regularization techniques. If the dataset is small, aggressive regularization like Dropout may lead to underfitting as there is limited data to learn from. In such cases, lighter forms of regularization or techniques like Early Stopping might be more appropriate.\n",
    "\n",
    "b. `Model Complexity`: The complexity of the model should also be taken into account. If the model is already simple, adding too much regularization may hinder its ability to learn useful patterns from the data. On the other hand, for very deep and complex models, strong regularization like Dropout might be necessary to prevent overfitting.\n",
    "\n",
    "c. `Computational Resources`: Some regularization techniques, such as Dropout, introduce randomness and require multiple forward passes during training, which can increase computational overhead. If computational resources are limited, lighter regularization techniques like L2 regularization or Batch Normalization might be more feasible.\n",
    "\n",
    "d. `Task Requirements`: The nature of the task and the desired model behavior also influence the choice of regularization. For tasks where interpretability is crucial, techniques like L1 regularization can help promote sparsity in the model's weights, making it easier to understand the learned features.\n",
    "\n",
    "e. `Model Performance`: Regularization techniques should be evaluated based on their impact on model performance. It's essential to monitor both training and validation metrics to ensure the chosen regularization does not lead to underfitting or overfitting.\n",
    "\n",
    "f. `Domain Knowledge`: Understanding the domain and the dataset can provide insights into which regularization technique might be more appropriate. For example, in tasks where certain features are known to be less relevant, Dropout can be used to discourage the model from relying on those features.\n",
    "\n",
    "g. `Ensemble Techniques`: In some cases, a combination of regularization techniques or an ensemble of models with different regularization settings can be beneficial. Ensemble methods can help reduce the risk of relying too heavily on a single regularization strategy and improve overall model performance.\n",
    "\n",
    "In conclusion, choosing the appropriate regularization technique for a deep learning task requires careful consideration of dataset size, model complexity, computational resources, task requirements, and domain knowledge. It's essential to strike a balance between preventing overfitting and allowing the model to learn relevant patterns from the data. Regularization techniques should be evaluated through experimentation and validation to ensure the best performance for the specific task at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf85034-eb38-4d02-af53-c87e3ad693b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
